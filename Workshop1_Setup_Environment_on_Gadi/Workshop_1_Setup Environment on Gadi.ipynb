{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702d07a4-a158-4514-8a3d-64c89941fec8",
   "metadata": {},
   "source": [
    "# Workshop 1: Setup Environment on Gadi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de95ddca-65be-4043-951b-60ac21cfc808",
   "metadata": {},
   "source": [
    "- know your hardware\n",
    "- set up conda environment on Gadi\n",
    "- set up port forwording on Gadi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98610bc-8452-4187-99ac-afe20024e27c",
   "metadata": {},
   "source": [
    "## Know your hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93c235d-33cf-4108-947e-0689e7051abc",
   "metadata": {},
   "source": [
    "In terminal, you can check your cpu info by using command 'lscpu'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c3264b-1396-4ea2-840d-171eb4a679f3",
   "metadata": {},
   "source": [
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">[kd1348@gadi-cpu-clx-1519 kd1348]$ lscpu\n",
    "Architecture:        x86_64\n",
    "CPU op-mode(s):      32-bit, 64-bit\n",
    "Byte Order:          Little Endian\n",
    "CPU(s):              96\n",
    "On-line CPU(s) list: 0-95\n",
    "Thread(s) per core:  2\n",
    "Core(s) per socket:  24\n",
    "Socket(s):           2\n",
    "NUMA node(s):        4\n",
    "Vendor ID:           GenuineIntel\n",
    "CPU family:          6\n",
    "Model:               85\n",
    "Model name:          Intel(R) Xeon(R) Platinum 8274 CPU @ 3.20GHz\n",
    "Stepping:            7\n",
    "CPU MHz:             1366.469\n",
    "CPU max MHz:         4000.0000\n",
    "CPU min MHz:         1200.0000\n",
    "BogoMIPS:            6400.00\n",
    "Virtualization:      VT-x\n",
    "L1d cache:           32K\n",
    "L1i cache:           32K\n",
    "L2 cache:            1024K\n",
    "L3 cache:            36608K\n",
    "NUMA node0 CPU(s):   0-3,7,8,12-14,18-20,48-51,55,56,60-62,66-68\n",
    "NUMA node1 CPU(s):   4-6,9-11,15-17,21-23,52-54,57-59,63-65,69-71\n",
    "NUMA node2 CPU(s):   24-27,31-33,37-39,43,44,72-75,79-81,85-87,91,92\n",
    "NUMA node3 CPU(s):   28-30,34-36,40-42,45-47,76-78,82-84,88-90,93-95\n",
    "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single intel_ppin ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb intel_pt avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts hwp hwp_act_window hwp_epp hwp_pkg_req pku ospke avx512_vnni md_clear flush_l1d arch_capabilities\n",
    "</code>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d17f10-8727-487d-8aa9-578366ca4a95",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Quiz:</b> in our pbs job script we only require 12 cpus, but it is showing we have 0-95 in total 96 cpus available. \n",
    "Why is that?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4936594b-cd1b-4424-881d-7773ab8207e6",
   "metadata": {},
   "source": [
    "To inspect the CPU and Memory utilisation rate of a running job, use \n",
    "\n",
    "``\n",
    "'nqstat_anu' + job_id\n",
    "``\n",
    "\n",
    "It is encouraged to monitor our jobss CPU and Memory utilisation rate. Normally, a low utilisation means current resources are not used efficiently. However, a 100% utilisation rate doesn't guarentee for efficient usage of requested resources. For example,the output below indicates the job named jupyter_notebook used only 0% of the compute capcity of the requested 12 cpus in the past 17 minutes 39 seconds. And the peak memory usage is only 400MB over the allocated 100GB. **The low utilisation of the compute resources is the main reason that running interactive development environment like jupyter notebook is not encouraged**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30232500-2b43-453b-9032-3648551b134f",
   "metadata": {},
   "source": [
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">[kd1348@gadi-cpu-clx-1519 kd1348]$ nqstat_anu 50113772\n",
    "                                 %CPU  WallTime  Time Lim     RSS    mem memlim cpus\n",
    " 50113772 R kd1348 vp91 jupyter_   0  00:17:39  02:00:00  400MB  400MB  100GB    12\n",
    "</code>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fd3736-2300-42b0-a9cb-a5be73ef25ed",
   "metadata": {},
   "source": [
    "or you can use command 'htop' ( an interactive process viewer) to monitor processes running on your node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24802fd9-a581-427e-8f0f-a56323367539",
   "metadata": {},
   "source": [
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">[kd1348@gadi-cpu-clx-1519 kd1348]$ htop\n",
    "</code>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7173c0-f4da-462f-a5c5-5c88eaec2211",
   "metadata": {},
   "source": [
    "if you want to run a linux command within the jupyter notebook code cell, you will need to add '!' in front of your command\n",
    "\n",
    "for example, if you want to check the memory usage of your current hardware:\n",
    "\n",
    "in terminal:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">[kd1348@gadi-cpu-clx-1519 kd1348]$ free -g\n",
    "              total        used        free      shared  buff/cache   available\n",
    "Mem:            188          44          75           0          68         141\n",
    "Swap:            15           6           9\n",
    "</code>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e7b8bf-3516-484d-b477-b48f80bd34cb",
   "metadata": {},
   "source": [
    "in jupyter notebook code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5665f926-f8b0-4fb4-9c05-3096fc3bb547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:            376          24         226           0         125         349\n",
      "Swap:            15           0          15\n"
     ]
    }
   ],
   "source": [
    "# print the memory usage of your current hardware\n",
    "! free -g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfba88f1-b329-4226-bc55-ccec973bc7a4",
   "metadata": {},
   "source": [
    "Another useful command to check your GPU's status is: nvidia-smi\n",
    "- check your gpu Driver version and CUDA version\n",
    "- verify your system has loaded dependencies correctly\n",
    "- check your graphic memory usage\n",
    "- check your DL model's efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb09a29d-b161-4a88-b6f2-8f6826099c3a",
   "metadata": {},
   "source": [
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">[kd1348@gadi-gpu-v100-0089 DeepTF]$ nvidia-smi\n",
    "Fri Jul  1 12:02:29 2022       \n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  Tesla V100-SXM2...  On   | 00000000:3E:00.0 Off |                    0 |\n",
    "| N/A   36C    P0    43W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+                                                                      +-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "|  No running processes found                                                 |\n",
    "+-----------------------------------------------------------------------------+\n",
    "</code>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb0560-5020-4c73-a91a-f262999fbabe",
   "metadata": {},
   "source": [
    "to monitor your gpu usage, you can either use: \n",
    "```shell\n",
    "watch -n0.5 nvidia-smi\n",
    "```\n",
    "or\n",
    "```shell\n",
    "nvidia-smi -l\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6790283f-3803-46a7-8dbe-5454a22f8635",
   "metadata": {
    "tags": []
   },
   "source": [
    "For more information about Linux command guide on Gadi, Please check https://opus.nci.org.au/display/Help/Linux+Command+Quick+Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfdffcd-3774-46ea-af20-20aed3a929e0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Quiz:</b> Try to print your GPU status inside the code cell, and discuss with your peers what you have found.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4b8d22-8de3-4b7e-a734-f841ee9f831f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul  7 15:40:57 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    43W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "Thu Jul  7 15:41:02 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    43W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "Thu Jul  7 15:41:07 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    43W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "Thu Jul  7 15:41:12 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    43W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b741e044-4664-4223-9d5f-1f15358ca19f",
   "metadata": {},
   "source": [
    "## (Optional) Setup conda environment on Gadi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0723161-c7b4-43a4-abe1-d764429ab013",
   "metadata": {},
   "source": [
    "Conda is an cross-platform, software package manager and environment management system.\n",
    "\n",
    "To install conda (assumed you have the Anaconda installer in your current working directory):\n",
    "\n",
    "run the installer and follow the prompt\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">$ bash Anaconda-latest-Linux-x86_64.sh\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "To activate conda:\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">$ conda activate\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "After activate conda, your terminal should change from \n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">[kd1348@gadi-cpu-clx-0323 kd1348]$\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "\n",
    "to\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">(base) [kd1348@gadi-cpu-clx-0323 kd1348]$ \n",
    "</code>\n",
    "</p>\n",
    "\n",
    "\n",
    "\"(base)\" indicates Conda default environement is activated, which contain a Python installation and some core system libraries and dependencied of Conda. For best preactice, it is recommended to avoid installing packages in your Conda base environment.\n",
    "\n",
    "To create a new conda environment (named \"new_env\"):\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">$ conda create --name new_env\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "\n",
    "To activate your new environment:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">$ conda activate new_env\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "After activation, you will find \"(new_env)\" shows at the begining of your terminal, which indicate your current active conda environment has changed from \"base\" to \"new_env\"\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">(new_env) [kd1348@gadi-cpu-clx-0323 kd1348]$ \n",
    "</code>\n",
    "</p>\n",
    "\n",
    "\n",
    "To quit from your new environment to base environment:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">$ conda deactivate\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "To check available conda environments:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">(base) [kd1348@gadi-cpu-clx-0323 kd1348]$ conda env list\n",
    "</code>\n",
    "</p>\n",
    "    \n",
    "An example output would be:\n",
    "    \n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\"># conda environments:\n",
    "#\n",
    "base                  *  /g/data/ik06/stark/anaconda3\n",
    "deep_tf                  /g/data/ik06/stark/anaconda3/envs/deep_tf\n",
    "leopard                  /g/data/ik06/stark/anaconda3/envs/leopard\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "To install package such as scikit learn ('-c' define the channel which tell conda where to download the package. In this case we are using 'conda-forge' channel. For more information about 'conda-forge', please check https://conda-forge.org/docs/index.html )\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">$ conda install -c conda-forge scikit-learn\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "To inspect packages installed in current environment:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">$ conda list\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "In addition to package manager, Conda is also widely used to manage environments.\n",
    "\n",
    "If you want to make sure your environment is consistent across platforms, you can export your current environment to an environment.yml file. And in another platform, you can ask conda to create an identical environment based on the environment.yml file. \n",
    "\n",
    "For example, \n",
    "\n",
    "to export current environment to .yml file:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">$ conda env export > deep_tf.yml\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "to create a new conda environment using the deep_tf.yml file:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">$ conda env create -f deep_tf.yml\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "For more information about Conda, please check https://docs.conda.io/projects/conda/en/latest/index.html ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520275d9-72ed-4b1f-96d8-507aee1cf3d7",
   "metadata": {},
   "source": [
    "## Setup port forwording on Gadi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140f72ff-e272-49e4-8f51-05829bf8d20b",
   "metadata": {},
   "source": [
    "step 1: In **login node**, setup jupyter server and setup your jupyter server's password\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">$ jupyter server --generate-config //generate a default jupyter config file\n",
    "\n",
    "$ jupyter server password // follow the prompt to set up a password for the server, different from your gadi password\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "step 2: In **login node**, modify the gadi pbs job script (*jupyter_cpu_setup.pbs*)\n",
    "\n",
    "    - change the conda location path to your own conda environment path\n",
    "    - change the path to your port forwarding script\n",
    "\n",
    "step 3: In **login node**, submit your job script\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">$ qsub jupyter_cpu_setup.pbs\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "step 4: In **login node**, once your job start, you should find a new file named 'client_cmd' in the same folder you submit your job script. Inside the file, you should find a command like below:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">ssh -N -L 8337:gadi-gpu-v100-0089.gadi.nci.org.au:8337 kd1348@gadi.nci.org.au\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "step 5: In **your local terminal**, paste the command above and run.\n",
    "\n",
    "step 6: In **your browser**, go to address: localhost:port_number and enter your jupyter server password.\n",
    "\n",
    "In this example,\n",
    "``` \n",
    "localhost:8337\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f0b462-743a-4bfa-9bfb-ef1f25626d8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Task: Setup your development environment on Gadi.\n",
    "    \n",
    "- 1. ssh to Gadi and make a copy of the folder AI-ML-Applications-on-Gadi/ ()\n",
    "- 2. install Conda and create a new Conda environment based on the 'deep_tf.yml'\n",
    "- 3. setup jupyter server and connect to your server through ssh tunnel\n",
    "    </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedb8388-87b2-4d4c-b07f-5a3766eef02c",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "1. Inspect the hardware and monitor your hardware\n",
    "2. Setup python environment using Conda\n",
    "3. Setup port forwarding on Gadi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2b17eb",
   "metadata": {},
   "source": [
    "reference:\n",
    "\n",
    "- [https://www.digitalocean.com/community/tutorials/how-to-install-run-connect-to-jupyter-notebook-on-remote-server](https://www.digitalocean.com/community/tutorials/how-to-install-run-connect-to-jupyter-notebook-on-remote-server)\n",
    "- [https://nci-australia.teachable.com/courses/jupyterlab-on-gadi/lectures/36427924](https://nci-australia.teachable.com/courses/jupyterlab-on-gadi/lectures/36427924)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
